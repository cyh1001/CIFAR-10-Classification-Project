{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2ac12e-6ee2-44ee-bf49-6d91705fccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37b063f-3353-4ffa-8b49-8546c4bfcb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 数据增强\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# 加载CIFAR-10数据集\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 划分训练集和验证集（80%训练，20%验证）\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "valloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 类别名称（用于报告）\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd6fc18-9080-4bd9-bafd-224857a08f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义残差块\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 定义ResNet变体\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 48  # 初始通道从 32 增加到 64\n",
    "        self.conv1 = nn.Conv2d(3, 48, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(48)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 48, num_blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(block, 196, num_blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 192, num_blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block, 384, num_blocks[3], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)  # 添加 Dropout 防止过拟合\n",
    "        self.fc = nn.Linear(384 * block.expansion, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.dropout(out.view(out.size(0), -1))  # 在全连接层前应用 Dropout\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d5f881-c957-4574-a350-d09ddd98c3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
      "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
      "              ReLU-3           [-1, 48, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]          20,736\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 48, 32, 32]          20,736\n",
      "       BatchNorm2d-8           [-1, 48, 32, 32]              96\n",
      "              ReLU-9           [-1, 48, 32, 32]               0\n",
      "       BasicBlock-10           [-1, 48, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]          20,736\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 48, 32, 32]          20,736\n",
      "      BatchNorm2d-15           [-1, 48, 32, 32]              96\n",
      "             ReLU-16           [-1, 48, 32, 32]               0\n",
      "       BasicBlock-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18          [-1, 196, 16, 16]          84,672\n",
      "      BatchNorm2d-19          [-1, 196, 16, 16]             392\n",
      "             ReLU-20          [-1, 196, 16, 16]               0\n",
      "           Conv2d-21          [-1, 196, 16, 16]         345,744\n",
      "      BatchNorm2d-22          [-1, 196, 16, 16]             392\n",
      "           Conv2d-23          [-1, 196, 16, 16]           9,408\n",
      "      BatchNorm2d-24          [-1, 196, 16, 16]             392\n",
      "             ReLU-25          [-1, 196, 16, 16]               0\n",
      "       BasicBlock-26          [-1, 196, 16, 16]               0\n",
      "           Conv2d-27          [-1, 196, 16, 16]         345,744\n",
      "      BatchNorm2d-28          [-1, 196, 16, 16]             392\n",
      "             ReLU-29          [-1, 196, 16, 16]               0\n",
      "           Conv2d-30          [-1, 196, 16, 16]         345,744\n",
      "      BatchNorm2d-31          [-1, 196, 16, 16]             392\n",
      "             ReLU-32          [-1, 196, 16, 16]               0\n",
      "       BasicBlock-33          [-1, 196, 16, 16]               0\n",
      "           Conv2d-34            [-1, 192, 8, 8]         338,688\n",
      "      BatchNorm2d-35            [-1, 192, 8, 8]             384\n",
      "             ReLU-36            [-1, 192, 8, 8]               0\n",
      "           Conv2d-37            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-38            [-1, 192, 8, 8]             384\n",
      "           Conv2d-39            [-1, 192, 8, 8]          37,632\n",
      "      BatchNorm2d-40            [-1, 192, 8, 8]             384\n",
      "             ReLU-41            [-1, 192, 8, 8]               0\n",
      "       BasicBlock-42            [-1, 192, 8, 8]               0\n",
      "           Conv2d-43            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-44            [-1, 192, 8, 8]             384\n",
      "             ReLU-45            [-1, 192, 8, 8]               0\n",
      "           Conv2d-46            [-1, 192, 8, 8]         331,776\n",
      "      BatchNorm2d-47            [-1, 192, 8, 8]             384\n",
      "             ReLU-48            [-1, 192, 8, 8]               0\n",
      "       BasicBlock-49            [-1, 192, 8, 8]               0\n",
      "           Conv2d-50            [-1, 384, 4, 4]         663,552\n",
      "      BatchNorm2d-51            [-1, 384, 4, 4]             768\n",
      "             ReLU-52            [-1, 384, 4, 4]               0\n",
      "           Conv2d-53            [-1, 384, 4, 4]       1,327,104\n",
      "      BatchNorm2d-54            [-1, 384, 4, 4]             768\n",
      "           Conv2d-55            [-1, 384, 4, 4]          73,728\n",
      "      BatchNorm2d-56            [-1, 384, 4, 4]             768\n",
      "             ReLU-57            [-1, 384, 4, 4]               0\n",
      "       BasicBlock-58            [-1, 384, 4, 4]               0\n",
      "AdaptiveAvgPool2d-59            [-1, 384, 1, 1]               0\n",
      "          Dropout-60                  [-1, 384]               0\n",
      "           Linear-61                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 4,662,098\n",
      "Trainable params: 4,662,098\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 14.43\n",
      "Params size (MB): 17.78\n",
      "Estimated Total Size (MB): 32.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 创建模型实例（减少层数和通道数以控制参数<500万）\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 1])  # 每个阶段2个残差块\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 检查模型参数量\n",
    "summary(model, (3, 32, 32))  # 确保参数<500万"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d58a0-68f5-4042-81ec-cc60e979ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [100/625], Loss: 2.053\n",
      "Epoch [1/40], Step [200/625], Loss: 1.845\n",
      "Epoch [1/40], Step [300/625], Loss: 1.752\n",
      "Epoch [1/40], Step [400/625], Loss: 1.654\n",
      "Epoch [1/40], Step [500/625], Loss: 1.599\n",
      "Epoch [1/40], Step [600/625], Loss: 1.551\n",
      "Validation Accuracy: 46.96%\n",
      "Epoch [2/40], Step [100/625], Loss: 1.460\n",
      "Epoch [2/40], Step [200/625], Loss: 1.409\n",
      "Epoch [2/40], Step [300/625], Loss: 1.379\n",
      "Epoch [2/40], Step [400/625], Loss: 1.333\n",
      "Epoch [2/40], Step [500/625], Loss: 1.296\n",
      "Epoch [2/40], Step [600/625], Loss: 1.260\n",
      "Validation Accuracy: 50.52%\n",
      "Epoch [3/40], Step [100/625], Loss: 1.210\n",
      "Epoch [3/40], Step [200/625], Loss: 1.197\n",
      "Epoch [3/40], Step [300/625], Loss: 1.188\n",
      "Epoch [3/40], Step [400/625], Loss: 1.126\n",
      "Epoch [3/40], Step [500/625], Loss: 1.105\n",
      "Epoch [3/40], Step [600/625], Loss: 1.105\n",
      "Validation Accuracy: 58.97%\n",
      "Epoch [4/40], Step [100/625], Loss: 1.034\n",
      "Epoch [4/40], Step [200/625], Loss: 1.063\n",
      "Epoch [4/40], Step [300/625], Loss: 1.008\n",
      "Epoch [4/40], Step [400/625], Loss: 1.009\n",
      "Epoch [4/40], Step [500/625], Loss: 0.945\n",
      "Epoch [4/40], Step [600/625], Loss: 0.987\n",
      "Validation Accuracy: 65.40%\n",
      "Epoch [5/40], Step [100/625], Loss: 0.930\n",
      "Epoch [5/40], Step [200/625], Loss: 0.920\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, trainloader, valloader, num_epochs=40, device=device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)  # 添加权重衰减\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 每 10 epoch 降低学习率\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "        val_accuracies.append(val_acc)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_acc >= 94:  # 目标提升到 90%\n",
    "            break\n",
    "    \n",
    "    torch.save(model.state_dict(), 'resnet_model.pth')\n",
    "    print(\"Model saved as 'resnet_model.pth'\")\n",
    "    \n",
    "    return train_losses, val_accuracies\n",
    "\n",
    "train_losses, val_accuracies = train_model(model, trainloader, valloader)\n",
    "\n",
    "# 绘制损失和准确率曲线\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c850e3-36ee-4779-b4d7-8fcbdbc082d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 train_model 函数末尾添加\n",
    "torch.save(model.state_dict(), 'resnet_model.pth')\n",
    "print(\"Model saved as 'resnet_model.pth'\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# 加载自定义测试集\n",
    "test_pkl_path = './test_data/cifar_test_nolabel.pkl'\n",
    "data_dict = unpickle(test_pkl_path)\n",
    "images = data_dict[b'data']\n",
    "print(f\"Raw data shape: {images.shape}\")\n",
    "print(f\"Data type: {images.dtype}\")\n",
    "\n",
    "# 检查数值范围\n",
    "print(f\"Min value: {images.min()}, Max value: {images.max()}\")\n",
    "\n",
    "def predict_with_tta(model, testloader, device, num_augment=5):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ids = []\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    with torch.no_grad():\n",
    "        for inputs, batch_ids in testloader:\n",
    "            batch_preds = torch.zeros(inputs.size(0), 10, device=device)\n",
    "            for _ in range(num_augment):\n",
    "                aug_inputs = torch.stack([aug_transform(inputs[i].cpu()) for i in range(inputs.size(0))])\n",
    "                aug_inputs = aug_inputs.to(device)\n",
    "                outputs = model(aug_inputs)\n",
    "                batch_preds += outputs.softmax(dim=1)\n",
    "            _, predicted = torch.max(batch_preds, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            ids.extend(batch_ids.numpy())\n",
    "    return ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f473dc3-fac4-4401-83c0-0ec19620469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def unpickle(file):\n",
    "    print(f\"Loading {file}...\")\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    print(\"File loaded successfully.\")\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46d9ca-ebff-4fce-bdd4-f6919a003869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修正后的 CustomTestDataset\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, pkl_path, transform=None):\n",
    "        data_dict = unpickle(pkl_path)\n",
    "        self.images = data_dict[b'data']  # 直接使用 (10000, 32, 32, 3)\n",
    "        print(f\"Loaded images shape: {self.images.shape}\")\n",
    "        print(f\"Data type: {self.images.dtype}\")\n",
    "        print(f\"Min value: {self.images.min()}, Max value: {self.images.max()}\")\n",
    "        self.ids = list(range(len(self.images)))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]  # (32, 32, 3)\n",
    "        # 如果确认通道顺序是 BGR，可在此处反转为 RGB\n",
    "        # img = img[..., ::-1]\n",
    "        # img = self.images[..., ::-1]  # 取消注释此行如果需要 BGR -> RGB\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.ids[idx]\n",
    "\n",
    "# 测试集变换，与训练一致\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),  # 转换为 (C, H, W)\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 与 CIFAR-10 训练一致\n",
    "])\n",
    "\n",
    "# 加载测试数据\n",
    "test_pkl_path = './test_data/cifar_test_nolabel.pkl'\n",
    "print(f\"Initializing dataset with {test_pkl_path}\")\n",
    "test_dataset = CustomTestDataset(pkl_path=test_pkl_path, transform=test_transform)\n",
    "testloader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# 加载模型\n",
    "model.load_state_dict(torch.load('resnet_model.pth', weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "\n",
    "# # 使用 TTA 进行预测\n",
    "# start_time = time.time()\n",
    "# print(\"Starting predictions with TTA...\")\n",
    "# ids, predictions = predict_with_tta(model, testloader, device, num_augment=5)\n",
    "\n",
    "# print(f\"Prediction completed in {time.time() - start_time:.2f} seconds\")\n",
    "# submission = pd.DataFrame({'ID': ids, 'Labels': predictions})\n",
    "# submission.to_csv('submission_tta.csv', index=False)\n",
    "# print(\"Submission file 'submission_tta.csv' generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea1f97-fce4-445b-8db8-32771f6bbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "num_samples = len(test_dataset)\n",
    "predictions = []\n",
    "ids = []\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Starting predictions...\")\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader):\n",
    "        inputs, batch_ids = data[0].to(device), data[1]\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        ids.extend(batch_ids.numpy())\n",
    "        if i % 10 == 0:  # 每 10 个 batch 打印一次\n",
    "            print(f\"Processed batch {i}, time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(f\"Prediction completed in {time.time() - start_time:.2f} seconds\")\n",
    "submission = pd.DataFrame({'ID': ids, 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4fb167-9f61-4662-b4cc-7abda300ce27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b610d90-685e-42ac-8c68-74a7c24cc0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
